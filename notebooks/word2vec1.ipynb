{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "538e4ec8-7167-4bf8-8321-8024929c8e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f73bb80d-cef8-4252-b245-fe6051d6f7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    {'model_type': 'cbow', 'window': 2, 'vector_size': 100},\n",
    "    {'model_type': 'skipgram', 'window': 2, 'vector_size': 100},\n",
    "    {'model_type': 'cbow', 'window': 4, 'vector_size': 100},\n",
    "    {'model_type': 'skipgram', 'window': 4, 'vector_size': 100},\n",
    "    {'model_type': 'cbow', 'window': 2, 'vector_size': 300},\n",
    "    {'model_type': 'skipgram', 'window': 2, 'vector_size': 300},\n",
    "    {'model_type': 'cbow', 'window': 4, 'vector_size': 300},\n",
    "    {'model_type': 'skipgram', 'window': 4, 'vector_size': 300}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "431fbb7f-ad27-493d-b9ed-95931b78e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"lemmatized_sentences.csv\")\n",
    "df2 = pd.read_csv(\"stemmed_sentences.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85d57358-2eea-434e-89c7-d4c87024b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns = [\"0\"]\n",
    "\n",
    "# NaN değerleri ve boş stringleri temizle\n",
    "df1 = df1.dropna()\n",
    "df1 = df1[df1[\"0\"].str.strip() != \"\"]\n",
    "\n",
    "df2.columns = [\"0\"]\n",
    "\n",
    "# NaN değerleri ve boş stringleri temizle\n",
    "df2 = df2.dropna()\n",
    "df2 = df2[df2[\"0\"].str.strip() != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5bcac19-dc9b-4428-b1d3-272a4548d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doğru tokenizasyon fonksiyonu\n",
    "def proper_tokenize(text):\n",
    "    # Özel karakterleri kaldır ve küçük harfe çevir\n",
    "    text = re.sub(r'[^a-zA-ZğüşıöçĞÜŞİÖÇ\\s]', '', text.lower())\n",
    "    # NLTK ile tokenize et\n",
    "    tokens = word_tokenize(text)\n",
    "    # Stopwords'leri ve tek karakterli kelimeleri kaldır\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return [word for word in tokens if word not in stop_words and len(word) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f511bf53-e40c-49f3-bba0-bc4fbb15a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doğru tokenizasyon uygula\n",
    "df1['tokens'] = df1['0'].apply(proper_tokenize)\n",
    "df2['tokens'] = df2['0'].apply(proper_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7004bf88-ce39-43d6-a6d0-f097bc8316b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token listelerini oluştur\n",
    "tokenized_corpus_lemmatized = df1['tokens'].tolist()\n",
    "tokenized_corpus_stemmed = df2['tokens'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe5c6d16-68ee-4d6a-b797-672d31376fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_model(corpus, param, model_prefix):\n",
    "    model_type = param['model_type']\n",
    "    vector_size = param['vector_size']\n",
    "    window = param['window']\n",
    "    \n",
    "    # CBOW (sg=0) veya Skip-gram (sg=1)\n",
    "    sg = 0 if model_type == 'cbow' else 1\n",
    "\n",
    "    model = Word2Vec(\n",
    "        sentences=corpus,\n",
    "        vector_size=vector_size,\n",
    "        window=window,\n",
    "        min_count=1,\n",
    "        workers=4,\n",
    "        sg=sg\n",
    "    )\n",
    "\n",
    "    model_filename = f\"{model_prefix}_{model_type}_vs{vector_size}_w{window}.model\"\n",
    "    model.save(model_filename)\n",
    "    print(f\"Model saved as {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6deaa53a-45da-4589-be66-ef2ea66a5be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as lemmatized_model_cbow_vs100_w2.model\n",
      "Model saved as lemmatized_model_skipgram_vs100_w2.model\n",
      "Model saved as lemmatized_model_cbow_vs100_w4.model\n",
      "Model saved as lemmatized_model_skipgram_vs100_w4.model\n",
      "Model saved as lemmatized_model_cbow_vs300_w2.model\n",
      "Model saved as lemmatized_model_skipgram_vs300_w2.model\n",
      "Model saved as lemmatized_model_cbow_vs300_w4.model\n",
      "Model saved as lemmatized_model_skipgram_vs300_w4.model\n",
      "Model saved as stemmed_model_cbow_vs100_w2.model\n",
      "Model saved as stemmed_model_skipgram_vs100_w2.model\n",
      "Model saved as stemmed_model_cbow_vs100_w4.model\n",
      "Model saved as stemmed_model_skipgram_vs100_w4.model\n",
      "Model saved as stemmed_model_cbow_vs300_w2.model\n",
      "Model saved as stemmed_model_skipgram_vs300_w2.model\n",
      "Model saved as stemmed_model_cbow_vs300_w4.model\n",
      "Model saved as stemmed_model_skipgram_vs300_w4.model\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize edilmiş corpus ile modelleri eğitme ve kaydetme\n",
    "for param in parameters:\n",
    "    train_and_save_model(tokenized_corpus_lemmatized, param, \"lemmatized_model\")\n",
    "\n",
    "# Stemlenmiş corpus ile modelleri eğitme ve kaydetme\n",
    "for param in parameters:\n",
    "    train_and_save_model(tokenized_corpus_stemmed, param, \"stemmed_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3783c299-fcdf-4820-ab6a-1d69c9a36fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model dosyalarını yüklemek\n",
    "model_1 = Word2Vec.load(\"lemmatized_model_cbow_vs100_w2.model\")\n",
    "model_2 = Word2Vec.load(\"lemmatized_model_cbow_vs100_w4.model\")\n",
    "model_3 = Word2Vec.load(\"lemmatized_model_cbow_vs300_w2.model\")\n",
    "model_4 = Word2Vec.load(\"lemmatized_model_cbow_vs300_w4.model\")\n",
    "model_5 = Word2Vec.load(\"lemmatized_model_skipgram_vs100_w2.model\")\n",
    "model_6 = Word2Vec.load(\"lemmatized_model_skipgram_vs100_w4.model\")\n",
    "model_7 = Word2Vec.load(\"lemmatized_model_skipgram_vs300_w2.model\")\n",
    "model_8 = Word2Vec.load(\"lemmatized_model_skipgram_vs300_w4.model\")\n",
    "model_9  = Word2Vec.load(\"stemmed_model_cbow_vs100_w2.model\")\n",
    "model_10 = Word2Vec.load(\"stemmed_model_cbow_vs100_w4.model\")\n",
    "model_11 = Word2Vec.load(\"stemmed_model_cbow_vs300_w2.model\")\n",
    "model_12 = Word2Vec.load(\"stemmed_model_cbow_vs300_w4.model\")\n",
    "model_13 = Word2Vec.load(\"stemmed_model_skipgram_vs100_w2.model\")\n",
    "model_14 = Word2Vec.load(\"stemmed_model_skipgram_vs100_w4.model\")\n",
    "model_15 = Word2Vec.load(\"stemmed_model_skipgram_vs300_w2.model\")\n",
    "model_16 = Word2Vec.load(\"stemmed_model_skipgram_vs300_w4.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69b609b0-fde1-45e1-861a-b2b0a74f0094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'heart' kelimesi ile en benzer 3 kelimeyi ve skorlarını yazdırmak\n",
    "def print_similar_words(model, model_name):\n",
    "    similarity = model.wv.most_similar(\"heart\", topn=3)\n",
    "    print(f\"\\n{model_name} Modeli - 'heart' ile En Benzer 3 Kelime:\")\n",
    "    for word, score in similarity:\n",
    "        print(f\"Kelime: {word}, Benzerlik Skoru: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c9d5191-77b4-42b9-8af9-4c9a978d54c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemmatized CBOW Window 2 Dim 100 Modeli - 'heart' ile En Benzer 3 Kelime:\n",
      "Kelime: toxic, Benzerlik Skoru: 0.2569843530654907\n",
      "Kelime: cc, Benzerlik Skoru: 0.22399276494979858\n",
      "Kelime: renal, Benzerlik Skoru: 0.18181410431861877\n",
      "\n",
      "Stemmed Skipgram Window 4 Dim 100 Modeli - 'heart' ile En Benzer 3 Kelime:\n",
      "Kelime: toxic, Benzerlik Skoru: 0.2554498612880707\n",
      "Kelime: cc, Benzerlik Skoru: 0.22555696964263916\n",
      "Kelime: renal, Benzerlik Skoru: 0.1849018782377243\n",
      "\n",
      "Lemmatized Skipgram Window 2 Dim 300 Modeli - 'heart' ile En Benzer 3 Kelime:\n",
      "Kelime: kidney, Benzerlik Skoru: 0.13194966316223145\n",
      "Kelime: pleural, Benzerlik Skoru: 0.12958508729934692\n",
      "Kelime: principal, Benzerlik Skoru: 0.11510880291461945\n",
      "\n",
      "lemmatized skipgram window 4 dim 100 Modeli - 'heart' ile En Benzer 3 Kelime:\n",
      "Kelime: kidney, Benzerlik Skoru: 0.13661669194698334\n",
      "Kelime: pleural, Benzerlik Skoru: 0.12958277761936188\n",
      "Kelime: principal, Benzerlik Skoru: 0.11802059412002563\n",
      "\n",
      "lemmatized cbow window 2 dim 300 Modeli - 'heart' ile En Benzer 3 Kelime:\n",
      "Kelime: toxic, Benzerlik Skoru: 0.26113224029541016\n",
      "Kelime: cc, Benzerlik Skoru: 0.2422710657119751\n",
      "Kelime: pulmonary, Benzerlik Skoru: 0.21879985928535461\n",
      "\n",
      "lemmatizedskipgramwindow 2 dim300 Modeli - 'heart' ile En Benzer 3 Kelime:\n",
      "Kelime: mcc, Benzerlik Skoru: 0.5650423765182495\n",
      "Kelime: mv, Benzerlik Skoru: 0.5601353645324707\n",
      "Kelime: diagnosis, Benzerlik Skoru: 0.5422874093055725\n",
      "\n",
      "lemmatized_cbow_window 4_dim300 Modeli - 'heart' ile En Benzer 3 Kelime:\n",
      "Kelime: kidney, Benzerlik Skoru: 0.16446584463119507\n",
      "Kelime: pleural, Benzerlik Skoru: 0.13619357347488403\n",
      "Kelime: ami, Benzerlik Skoru: 0.12890131771564484\n",
      "\n",
      "lemmatized_skipgram_window4_dim300.model Modeli - 'heart' ile En Benzer 3 Kelime:\n",
      "Kelime: mcc, Benzerlik Skoru: 0.5384475588798523\n",
      "Kelime: severe, Benzerlik Skoru: 0.522430419921875\n",
      "Kelime: procedure, Benzerlik Skoru: 0.5169084072113037\n",
      "\n",
      "stemmed_cbow_window2_dim100 Modeli - 'heart' ile En Benzer 3 Kelime:\n",
      "Kelime: effus, Benzerlik Skoru: 0.25113391876220703\n",
      "Kelime: age, Benzerlik Skoru: 0.24762146174907684\n",
      "Kelime: cc, Benzerlik Skoru: 0.20224438607692719\n",
      "\n",
      "stemmed_skipgram_window2_dim100 Modeli - 'heart' ile En Benzer 3 Kelime:\n",
      "Kelime: age, Benzerlik Skoru: 0.2554771900177002\n",
      "Kelime: effus, Benzerlik Skoru: 0.2548333704471588\n",
      "Kelime: cc, Benzerlik Skoru: 0.2133544236421585\n",
      "\n",
      "stemmed_cbow_window4_dim100 Modeli - 'heart' ile En Benzer 3 Kelime:\n",
      "Kelime: diagnos, Benzerlik Skoru: 0.15325747430324554\n",
      "Kelime: percutan, Benzerlik Skoru: 0.12382856756448746\n",
      "Kelime: urinari, Benzerlik Skoru: 0.12122058868408203\n",
      "\n",
      "stemmed_skipgram_window4_dim100 Modeli - 'heart' ile En Benzer 3 Kelime:\n",
      "Kelime: diagnos, Benzerlik Skoru: 0.1660250723361969\n",
      "Kelime: mcc, Benzerlik Skoru: 0.15213708579540253\n",
      "Kelime: urinari, Benzerlik Skoru: 0.14043866097927094\n",
      "\n",
      "stemmed_cbow_window2_dim300 Modeli - 'heart' ile En Benzer 3 Kelime:\n",
      "Kelime: age, Benzerlik Skoru: 0.2818295657634735\n",
      "Kelime: effus, Benzerlik Skoru: 0.26450249552726746\n",
      "Kelime: cardiovascular, Benzerlik Skoru: 0.26378318667411804\n",
      "\n",
      "stemmed_skipgram_window2_dim300 Modeli - 'heart' ile En Benzer 3 Kelime:\n",
      "Kelime: tract, Benzerlik Skoru: 0.6467698812484741\n",
      "Kelime: mcc, Benzerlik Skoru: 0.6436576843261719\n",
      "Kelime: disord, Benzerlik Skoru: 0.6399674415588379\n",
      "\n",
      "stemmed_cbow_window4_dim300 Modeli - 'heart' ile En Benzer 3 Kelime:\n",
      "Kelime: mcc, Benzerlik Skoru: 0.241950124502182\n",
      "Kelime: diagnos, Benzerlik Skoru: 0.20158280432224274\n",
      "Kelime: percutan, Benzerlik Skoru: 0.19952939450740814\n",
      "\n",
      "stemmed_skipgram_window4_dim300 Modeli - 'heart' ile En Benzer 3 Kelime:\n",
      "Kelime: mcc, Benzerlik Skoru: 0.6878718137741089\n",
      "Kelime: disord, Benzerlik Skoru: 0.6594924926757812\n",
      "Kelime: procedur, Benzerlik Skoru: 0.6565802097320557\n"
     ]
    }
   ],
   "source": [
    "# 16 model için benzer kelimeleri yazdır\n",
    "print_similar_words(model_1, \"Lemmatized CBOW Window 2 Dim 100\")\n",
    "print_similar_words(model_2, \"Stemmed Skipgram Window 4 Dim 100\")\n",
    "print_similar_words(model_3, \"Lemmatized Skipgram Window 2 Dim 300\")\n",
    "print_similar_words(model_4, \"lemmatized skipgram window 4 dim 100\")\n",
    "print_similar_words(model_5, \"lemmatized cbow window 2 dim 300\")\n",
    "print_similar_words(model_6, \"lemmatizedskipgramwindow 2 dim300\")\n",
    "print_similar_words(model_7, \"lemmatized_cbow_window 4_dim300\")\n",
    "print_similar_words(model_8, \"lemmatized_skipgram_window4_dim300.model\")\n",
    "print_similar_words(model_9, \"stemmed_cbow_window2_dim100\")\n",
    "print_similar_words(model_10, \"stemmed_skipgram_window2_dim100\")\n",
    "print_similar_words(model_11, \"stemmed_cbow_window4_dim100\")\n",
    "print_similar_words(model_12, \"stemmed_skipgram_window4_dim100\")\n",
    "print_similar_words(model_13, \"stemmed_cbow_window2_dim300\")\n",
    "print_similar_words(model_14, \"stemmed_skipgram_window2_dim300\")\n",
    "print_similar_words(model_15, \"stemmed_cbow_window4_dim300\")\n",
    "print_similar_words(model_16, \"stemmed_skipgram_window4_dim300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a411f2bb-a2dd-4b7e-a25a-ef84dd3d8bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
